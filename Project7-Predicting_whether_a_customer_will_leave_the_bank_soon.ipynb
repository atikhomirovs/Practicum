{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting whether a customer will leave the bank soon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we will use machine learning algorithms to develop a model that would analyze the data on clientsâ€™ past behavior and termination of contracts with the bank. The model will predict whether a customer will leave the bank soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents \n",
    "* [Data preparation]()\n",
    "* [Training the model without taking into account the imbalance]()\n",
    "* [Improving the quality of the model]()\n",
    "* [Final testing]()\n",
    "* [General Conclusion]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, will load the data and the libraries that we will use in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading all required libraries\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_auc_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data files into DataFrame\n",
    "df=pd.read_csv('/datasets/Churn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will display general data info and a sample of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "RowNumber          10000 non-null int64\n",
      "CustomerId         10000 non-null int64\n",
      "Surname            10000 non-null object\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             9091 non-null float64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# printing the general/summary information about the DataFrame\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>15574012</td>\n",
       "      <td>Chu</td>\n",
       "      <td>645</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>8.0</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>15592531</td>\n",
       "      <td>Bartlett</td>\n",
       "      <td>822</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>15656148</td>\n",
       "      <td>Obinna</td>\n",
       "      <td>376</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>15792365</td>\n",
       "      <td>He</td>\n",
       "      <td>501</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>4.0</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>15592389</td>\n",
       "      <td>H?</td>\n",
       "      <td>684</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "5          6    15574012       Chu          645     Spain    Male   44   \n",
       "6          7    15592531  Bartlett          822    France    Male   50   \n",
       "7          8    15656148    Obinna          376   Germany  Female   29   \n",
       "8          9    15792365        He          501    France    Male   44   \n",
       "9         10    15592389        H?          684    France    Male   27   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "5     8.0  113755.78              2          1               0   \n",
       "6     7.0       0.00              2          1               1   \n",
       "7     4.0  115046.74              4          1               0   \n",
       "8     4.0  142051.07              2          0               1   \n",
       "9     2.0  134603.88              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  \n",
       "5        149756.71       1  \n",
       "6         10062.80       0  \n",
       "7        119346.88       1  \n",
       "8         74940.50       0  \n",
       "9         71725.73       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing a sample of data\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns 'RowNumber', 'CustomerId', and 'Surname' have unique values for each row and are worthless for the algorithm. Therefore, we will drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping RowNumber', 'CustomerId', 'Surname' columns\n",
    "df=df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tenure column has a lot of missing values. Letâ€™s check which unique values this column has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  1.,  8.,  7.,  4.,  6.,  3., 10.,  5.,  9.,  0., nan])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing unique values of Tenure column\n",
    "df['Tenure'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column has only whole numbers and there does not seem to be a correlation between that column and other columns. We will replace the missing values in that column with the median value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing the missing values in Tenure column with median value.\n",
    "df['Tenure']=df['Tenure'].fillna(df['Tenure'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             10000 non-null float64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(3), int64(6), object(2)\n",
      "memory usage: 859.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# printing the general/summary information about the DataFrame to ensure that no missing values left\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will split the data frame into target and features subsets and prepare the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data frame into target and features subsets\n",
    "target=df['Exited']\n",
    "features=df.drop(['Exited'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use One-Hot Encoding to transform categorical features into numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming categorical features into numerical features\n",
    "features=pd.get_dummies(features, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will split the target and features sets into train, validation, and test subsets. And then we will check the balance of the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting data into training, validation and test sets\n",
    "features, features_test, target, target_test = train_test_split(features, target, test_size=0.2, random_state=12345)\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features, target, test_size=0.25, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 11)\n",
      "(2000, 11)\n",
      "(2000, 11)\n",
      "(6000,)\n",
      "(2000,)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "#printing the sizes of the sets to ensure that the data was splitted correctly\n",
    "print(features_train.shape)\n",
    "print(features_test.shape)\n",
    "print(features_valid.shape)\n",
    "print(target_train.shape)\n",
    "print(target_test.shape)\n",
    "print(target_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To standardize numerical features ('CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary') we will scale them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling numerical features\n",
    "pd.options.mode.chained_assignment = None\n",
    "numeric = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[numeric]) \n",
    "features_train[numeric]=scaler.transform(features_train[numeric])\n",
    "features_valid[numeric]=scaler.transform(features_valid[numeric])\n",
    "features_test[numeric]=scaler.transform(features_test[numeric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is ready. Next, we will examine the balance of classes. To do this we will count the values in the target set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4781\n",
       "1    1219\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#counting the values in the target set\n",
    "target_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the class are imbalanced. Firstly we will train the model without taking into account the imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model without taking into account the imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will investigate the quality of different models by changing hyperparameters. We will start with the Decision Tree and will train the model with different maximum depths in the range from 2 to 100. We will investigate the quality of each model by calculating f1 score on the validation data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best f1 score 0.5583596214511041 is achived with max_depth=7\n"
     ]
    }
   ],
   "source": [
    "#declaring variables for storing best max_depth and best f1 score\n",
    "\n",
    "best_max_depth=0\n",
    "best_f1=0\n",
    "\n",
    "#training models with different maximum depths in range from 2 to 100\n",
    "for i in range(2,100):\n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth=i)\n",
    "    model.fit(features_train, target_train) \n",
    "#calculating f1 score of the model on the validation data set    \n",
    "    predictions=model.predict(features_valid)\n",
    "    f1 = f1_score(target_valid, predictions)\n",
    "#if accuracy of the model is greater than previus best accuracy, updating best max_depth and best accuracy variables\n",
    "    if f1>best_f1:\n",
    "        best_max_depth=i\n",
    "        best_f1=f1\n",
    "\n",
    "#printing best f1 score\n",
    "print(f'Best f1 score {best_f1} is achived with max_depth={best_max_depth}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the best accuracy of 0.5583596214511041 is achieved with max_depth=7.\n",
    "\n",
    "Next, we will train the Random Forest with different numbers of estimators and with different depths. We will investigate the quality of each model by calculating f1 score on the validation data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best f1 score 0.5822784810126581 is achived with n_estimators=37 and max_depth=15\n"
     ]
    }
   ],
   "source": [
    "#declaring variables for storing best max_depth, best_max_depth and best f1 score\n",
    "\n",
    "best_n_estimators=0\n",
    "best_f1=0\n",
    "best_max_depth=0\n",
    "\n",
    "#training models with different maximum depths and n_estimators\n",
    "for i in range(2,50):\n",
    "    for j in range(2,20):\n",
    "        model = RandomForestClassifier(random_state=12345, n_estimators=i,max_depth=j) \n",
    "        model.fit(features_train, target_train) \n",
    "#calculating f1 score of the model on the validation data set    \n",
    "        predictions=model.predict(features_valid)\n",
    "        f1 = f1_score(target_valid, predictions)\n",
    "#if f1 score of the model is greater than previus best accuracy, updating best n_estimators and best f1 variables\n",
    "        if f1>best_f1:\n",
    "            best_n_estimators=i\n",
    "            best_max_depth=j\n",
    "            best_f1=f1\n",
    "\n",
    "#printing best f1 score\n",
    "print(f'Best f1 score {best_f1} is achived with n_estimators={best_n_estimators} and max_depth={best_max_depth}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the best accuracy 0.5822784810126581 is achieved with n_estimators=37 and max_depth=15.\n",
    "\n",
    "Finally, we will train the Logistic Regression will liblinear solver and will investigate the quality of the model by calculating f1 score on the validation data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30131826741996237"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training the model\n",
    "model = LogisticRegression(random_state=12345, solver='liblinear') \n",
    "model.fit(features_train, target_train) \n",
    "\n",
    "#calculating f1 score of the model on the validation data set \n",
    "predictions=model.predict(features_valid)\n",
    "f1 = f1_score(target_valid, predictions)\n",
    "\n",
    "#printing f1 score\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above calculations, our best model is Random Forest with 37 estimators and max_depth=15, and the model with the least accuracy is Logistic Regression.\n",
    "\n",
    "In the next step, we will check the quality of our best model using the test set. We will calculate f1 score and AUC-ROC metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1:0.550595238095238\n",
      "auc_roc: 0.8511979823455232\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "model = RandomForestClassifier(random_state=12345, n_estimators=37,max_depth=15) \n",
    "model.fit(features_train, target_train) \n",
    "\n",
    "#calculating f1 score and AUC-ROC of the model on the test data set    \n",
    "predictions=model.predict(features_test)\n",
    "f1 = f1_score(target_test, predictions)\n",
    "print(f'f1:{f1}')\n",
    "probabilities_test = model.predict_proba(features_test)\n",
    "auc_roc=roc_auc_score(target_test, probabilities_test[:, 1])\n",
    "print(f'auc_roc: {auc_roc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the f1 score is lower than the threshold f1 score (0.59). Next, we will try to improve the quality of the model by fixing class imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving the quality of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will adjust the class weight by using the class_weight argument. We will use only our best model - Random Forest with different numbers of estimators and with different depths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best f1 score 0.6038216560509554 is achived with n_estimators=37 and max_depth=10\n"
     ]
    }
   ],
   "source": [
    "#declaring variables for storing best max_depth, best_max_depth and best f1 score\n",
    "\n",
    "best_n_estimators=0\n",
    "best_f1=0\n",
    "best_max_depth=0\n",
    "\n",
    "#training models with different maximum depths and n_estimators\n",
    "for i in range(2,50):\n",
    "    for j in range(2,20):\n",
    "        model = RandomForestClassifier(random_state=12345, n_estimators=i,max_depth=j, class_weight='balanced') \n",
    "        model.fit(features_train, target_train) \n",
    "#calculating f1 score of the model on the validation data set    \n",
    "        predictions=model.predict(features_valid)\n",
    "        f1 = f1_score(target_valid, predictions)\n",
    "#if f1 score of the model is greater than previus best accuracy, updating best n_estimators and best f1 variables\n",
    "        if f1>best_f1:\n",
    "            best_n_estimators=i\n",
    "            best_max_depth=j\n",
    "            best_f1=f1\n",
    "\n",
    "#printing best f1 score\n",
    "print(f'Best f1 score {best_f1} is achived with n_estimators={best_n_estimators} and max_depth={best_max_depth}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the best accuracy 0.6038216560509554 is achived with n_estimators=37 and max_depth=10. It is above the threshold, but let's see if we can improve this further by using the upsampling technique. As we saw, there are 4 times more customers who stayed with the bank than those who left. We will build the function to upsample the imbalanced class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the function to upsample imbalanced class.\n",
    "def upsample(features, target, repeat):\n",
    "    \n",
    "#splitting feature and target into subset with different classes\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "#upsampling imbalanced class and concatinating the classes back together\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "\n",
    "#shuffling the sets\n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12345\n",
    "    )\n",
    "\n",
    "#returning the new balanced target and feature sets\n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "#using the function to upsample the training sets\n",
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will train our best model - Random Forest on new balanced training sets with different numbers of estimators and with different depths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best f1 score 0.6027027027027029 is achived with n_estimators=35 and max_depth=17\n"
     ]
    }
   ],
   "source": [
    "#declaring variables for storing best max_depth, best_max_depth and best f1 score\n",
    "\n",
    "best_n_estimators=0\n",
    "best_f1=0\n",
    "best_max_depth=0\n",
    "\n",
    "#training models with different maximum depths and n_estimators\n",
    "for i in range(2,50):\n",
    "    for j in range(2,20):\n",
    "        model = RandomForestClassifier(random_state=12345, n_estimators=i,max_depth=j, class_weight='balanced') \n",
    "        model.fit(features_upsampled, target_upsampled) \n",
    "#calculating f1 score of the model on the validation data set    \n",
    "        predictions=model.predict(features_valid)\n",
    "        f1 = f1_score(target_valid, predictions)\n",
    "#if f1 score of the model is greater than previus best accuracy, updating best n_estimators and best f1 variables\n",
    "        if f1>best_f1:\n",
    "            best_n_estimators=i\n",
    "            best_max_depth=j\n",
    "            best_f1=f1\n",
    "\n",
    "#printing best f1 score\n",
    "print(f'Best f1 score {best_f1} is achived with n_estimators={best_n_estimators} and max_depth={best_max_depth}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the best accuracy 0.6027027027027029 is achived with n_estimators=35 and max_depth=17. And this is slightly lower than it was before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will check the quality of our best model using the test set. We will calculate f1 score and AUC-ROC metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1:0.6339712918660286\n",
      "auc_roc: 0.8587135666122254\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=12345, n_estimators=37,max_depth=10, class_weight='balanced') \n",
    "model.fit(features_train, target_train) \n",
    "#calculating f1 score of the model on the validation data set    \n",
    "predictions=model.predict(features_test)\n",
    "f1 = f1_score(target_test, predictions)\n",
    "print(f'f1:{f1}')\n",
    "probabilities_test = model.predict_proba(features_test)\n",
    "auc_roc=roc_auc_score(target_test, probabilities_test[:, 1])\n",
    "print(f'auc_roc: {auc_roc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the model on the test set is even higher than on the validation set, and it is much higher than the threshold. At the same time, we see that auc_roc metrics improves in comparison with the model built before balancing the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General conclusion\n",
    "\n",
    "In this project, we used machine learning algorithms to develop a model that analyzed the data on clientsâ€™ past behavior and termination of contracts with the bank. The model was made to predict whether a customer will leave the bank soon.\n",
    "\n",
    "First of all, we observed the data, dropped the unnecessary columns, and addressed missing values. Next, we will split the data frame into the target and features subsets and prepare the features. We used One-Hot Encoding to transform categorical features into numerical features. To standardize numerical features, we scaled them.\n",
    "\n",
    "We found that the classes were imbalanced. Firstly, we trained the model without taking into account the imbalance. Using training and validation data sets, we investigated the quality of different models by changing hyperparameters. It appeared that in this case, the best model was Random Forest with 37 estimators and max_depth=15, and the model with the least accuracy is Logistic Regression. Next, we checked the quality of our best model using the test set. We calculated f1 score and AUC-ROC metrics. The f1 score (0.55) was lower than the threshold f1 score (0.59), so we tried to improve the quality of the model by fixing class imbalance. We used two different techniques to address class imbalance: class weight adjustments and upsampling. With class weight adjustments, we were able to achieve the best accuracy 0.6038216560509554 with n_estimators=37 and max_depth=10. And this was above the threshold.\n",
    "\n",
    "Finally, we checked the quality of our best model using the test set. The accuracy of the model on the test set was even higher than on the validation set, and it was much higher than the threshold. At the same time, we saw that auc_roc metrics improved in comparison with the model built before balancing the classes."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1318,
    "start_time": "2022-03-09T05:52:06.979Z"
   },
   {
    "duration": 35,
    "start_time": "2022-03-09T05:53:05.485Z"
   },
   {
    "duration": 90,
    "start_time": "2022-03-09T05:53:19.277Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-09T05:53:35.642Z"
   },
   {
    "duration": 42,
    "start_time": "2022-03-09T05:54:21.097Z"
   },
   {
    "duration": 546,
    "start_time": "2022-03-09T05:58:46.497Z"
   },
   {
    "duration": 261,
    "start_time": "2022-03-09T05:58:54.583Z"
   },
   {
    "duration": 35,
    "start_time": "2022-03-09T05:59:02.182Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-09T06:09:12.476Z"
   },
   {
    "duration": 90,
    "start_time": "2022-03-09T06:10:09.206Z"
   },
   {
    "duration": 286,
    "start_time": "2022-03-09T06:10:46.612Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-09T06:10:52.262Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-09T06:11:52.195Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-09T06:13:10.468Z"
   },
   {
    "duration": 16,
    "start_time": "2022-03-09T06:13:19.295Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-09T06:15:35.547Z"
   },
   {
    "duration": 20,
    "start_time": "2022-03-09T06:16:25.211Z"
   },
   {
    "duration": 17,
    "start_time": "2022-03-09T06:16:36.047Z"
   },
   {
    "duration": 18,
    "start_time": "2022-03-09T06:17:06.954Z"
   },
   {
    "duration": 16,
    "start_time": "2022-03-09T06:17:12.717Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-09T06:18:30.778Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-09T06:18:36.616Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-09T06:24:41.322Z"
   },
   {
    "duration": 333,
    "start_time": "2022-03-09T06:24:50.848Z"
   },
   {
    "duration": 447,
    "start_time": "2022-03-09T06:27:04.508Z"
   },
   {
    "duration": 1576,
    "start_time": "2022-03-09T06:27:33.572Z"
   },
   {
    "duration": 42,
    "start_time": "2022-03-09T06:27:35.151Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-09T06:27:35.196Z"
   },
   {
    "duration": 30,
    "start_time": "2022-03-09T06:27:35.211Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-09T06:27:35.244Z"
   },
   {
    "duration": 38,
    "start_time": "2022-03-09T06:27:35.252Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-09T06:27:35.293Z"
   },
   {
    "duration": 18,
    "start_time": "2022-03-09T06:27:35.304Z"
   },
   {
    "duration": 8,
    "start_time": "2022-03-09T06:27:35.325Z"
   },
   {
    "duration": 64,
    "start_time": "2022-03-09T06:27:35.336Z"
   },
   {
    "duration": 21,
    "start_time": "2022-03-09T06:27:35.402Z"
   },
   {
    "duration": 614,
    "start_time": "2022-03-09T06:27:39.425Z"
   },
   {
    "duration": 337,
    "start_time": "2022-03-09T06:28:33.652Z"
   },
   {
    "duration": 24,
    "start_time": "2022-03-09T06:29:02.096Z"
   },
   {
    "duration": 17,
    "start_time": "2022-03-09T06:29:04.819Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-09T06:34:21.394Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-09T06:35:43.648Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-09T06:36:13.632Z"
   },
   {
    "duration": 270,
    "start_time": "2022-03-09T06:37:56.958Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-09T06:38:15.537Z"
   },
   {
    "duration": 9,
    "start_time": "2022-03-09T06:38:39.250Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-09T06:41:03.676Z"
   },
   {
    "duration": 284,
    "start_time": "2022-03-09T06:47:00.876Z"
   },
   {
    "duration": 3492,
    "start_time": "2022-03-09T06:48:25.251Z"
   },
   {
    "duration": 3661,
    "start_time": "2022-03-09T06:53:39.731Z"
   },
   {
    "duration": 47689,
    "start_time": "2022-03-09T06:58:21.784Z"
   },
   {
    "duration": 12594,
    "start_time": "2022-03-09T06:59:38.942Z"
   },
   {
    "duration": 1032,
    "start_time": "2022-03-11T05:26:42.183Z"
   },
   {
    "duration": 40,
    "start_time": "2022-03-11T05:26:43.217Z"
   },
   {
    "duration": 8,
    "start_time": "2022-03-11T05:26:43.258Z"
   },
   {
    "duration": 17,
    "start_time": "2022-03-11T05:26:43.267Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-11T05:26:43.285Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-11T05:26:43.290Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-11T05:26:43.297Z"
   },
   {
    "duration": 11,
    "start_time": "2022-03-11T05:26:43.304Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-11T05:26:43.317Z"
   },
   {
    "duration": 15,
    "start_time": "2022-03-11T05:26:43.322Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-11T05:26:43.338Z"
   },
   {
    "duration": 16,
    "start_time": "2022-03-11T05:26:43.350Z"
   },
   {
    "duration": 39,
    "start_time": "2022-03-11T05:26:43.367Z"
   },
   {
    "duration": 9,
    "start_time": "2022-03-11T05:26:43.408Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-11T05:26:43.418Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-11T05:26:43.424Z"
   },
   {
    "duration": 2562,
    "start_time": "2022-03-11T05:26:43.432Z"
   },
   {
    "duration": 4964,
    "start_time": "2022-03-11T05:26:55.227Z"
   },
   {
    "duration": 98,
    "start_time": "2022-03-11T05:30:55.070Z"
   },
   {
    "duration": 105860,
    "start_time": "2022-03-11T05:31:02.591Z"
   },
   {
    "duration": 2481,
    "start_time": "2022-03-11T05:35:15.651Z"
   },
   {
    "duration": 647,
    "start_time": "2022-03-11T05:35:42.544Z"
   },
   {
    "duration": 23,
    "start_time": "2022-03-11T05:36:12.803Z"
   },
   {
    "duration": 235,
    "start_time": "2022-03-11T05:39:07.766Z"
   },
   {
    "duration": 221,
    "start_time": "2022-03-11T05:45:06.853Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-11T05:48:02.891Z"
   },
   {
    "duration": 510,
    "start_time": "2022-03-11T05:52:02.900Z"
   },
   {
    "duration": 524,
    "start_time": "2022-03-11T05:52:15.431Z"
   },
   {
    "duration": 3,
    "start_time": "2022-03-11T05:52:47.819Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-11T05:52:55.152Z"
   },
   {
    "duration": 312,
    "start_time": "2022-03-11T05:54:03.854Z"
   },
   {
    "duration": 3,
    "start_time": "2022-03-11T05:57:34.870Z"
   },
   {
    "duration": 637,
    "start_time": "2022-03-11T06:01:59.730Z"
   },
   {
    "duration": 3,
    "start_time": "2022-03-11T06:02:44.286Z"
   },
   {
    "duration": 323,
    "start_time": "2022-03-11T06:02:50.688Z"
   },
   {
    "duration": 235,
    "start_time": "2022-03-11T06:03:37.134Z"
   },
   {
    "duration": 232,
    "start_time": "2022-03-11T06:03:59.199Z"
   },
   {
    "duration": 237,
    "start_time": "2022-03-11T06:08:40.954Z"
   },
   {
    "duration": 320,
    "start_time": "2022-03-11T06:10:06.880Z"
   },
   {
    "duration": 320,
    "start_time": "2022-03-11T06:12:31.811Z"
   },
   {
    "duration": 236,
    "start_time": "2022-03-11T06:15:19.267Z"
   },
   {
    "duration": 3,
    "start_time": "2022-03-11T06:18:40.337Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-11T06:24:00.541Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-11T06:27:23.954Z"
   },
   {
    "duration": 9,
    "start_time": "2022-03-11T06:36:53.505Z"
   },
   {
    "duration": 11,
    "start_time": "2022-03-11T06:37:16.204Z"
   },
   {
    "duration": 11,
    "start_time": "2022-03-11T06:40:26.383Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-11T06:44:03.759Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-11T06:45:11.827Z"
   },
   {
    "duration": 238,
    "start_time": "2022-03-11T06:55:25.434Z"
   },
   {
    "duration": 109129,
    "start_time": "2022-03-11T07:03:08.141Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-11T07:14:27.881Z"
   },
   {
    "duration": 151155,
    "start_time": "2022-03-11T07:17:07.657Z"
   },
   {
    "duration": 290,
    "start_time": "2022-03-11T07:24:27.530Z"
   },
   {
    "duration": 1024,
    "start_time": "2022-03-11T07:59:36.981Z"
   },
   {
    "duration": 29,
    "start_time": "2022-03-11T07:59:38.007Z"
   },
   {
    "duration": 8,
    "start_time": "2022-03-11T07:59:38.038Z"
   },
   {
    "duration": 17,
    "start_time": "2022-03-11T07:59:38.048Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-11T07:59:38.067Z"
   },
   {
    "duration": 8,
    "start_time": "2022-03-11T07:59:38.073Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-11T07:59:38.102Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-11T07:59:38.108Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-11T07:59:38.118Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-11T07:59:38.124Z"
   },
   {
    "duration": 16,
    "start_time": "2022-03-11T07:59:38.138Z"
   },
   {
    "duration": 9,
    "start_time": "2022-03-11T07:59:38.155Z"
   },
   {
    "duration": 36,
    "start_time": "2022-03-11T07:59:38.166Z"
   },
   {
    "duration": 8,
    "start_time": "2022-03-11T07:59:38.204Z"
   },
   {
    "duration": 2510,
    "start_time": "2022-03-11T07:59:38.214Z"
   },
   {
    "duration": 108146,
    "start_time": "2022-03-11T07:59:40.726Z"
   },
   {
    "duration": 36,
    "start_time": "2022-03-11T08:01:28.873Z"
   },
   {
    "duration": 426,
    "start_time": "2022-03-11T08:01:28.911Z"
   },
   {
    "duration": 110162,
    "start_time": "2022-03-11T08:01:29.339Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-11T08:03:19.503Z"
   },
   {
    "duration": 153508,
    "start_time": "2022-03-11T08:03:19.517Z"
   },
   {
    "duration": 302,
    "start_time": "2022-03-11T08:05:53.026Z"
   },
   {
    "duration": 1345,
    "start_time": "2022-03-12T00:26:39.981Z"
   },
   {
    "duration": 30,
    "start_time": "2022-03-12T00:26:41.328Z"
   },
   {
    "duration": 22,
    "start_time": "2022-03-12T00:26:41.360Z"
   },
   {
    "duration": 28,
    "start_time": "2022-03-12T00:26:41.385Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-12T00:26:41.415Z"
   },
   {
    "duration": 8,
    "start_time": "2022-03-12T00:26:41.422Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-12T00:26:41.433Z"
   },
   {
    "duration": 46,
    "start_time": "2022-03-12T00:26:41.443Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-12T00:26:41.493Z"
   },
   {
    "duration": 20,
    "start_time": "2022-03-12T00:26:41.501Z"
   },
   {
    "duration": 11,
    "start_time": "2022-03-12T00:26:41.524Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-12T00:26:41.537Z"
   },
   {
    "duration": 69,
    "start_time": "2022-03-12T00:26:41.545Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-12T00:26:41.616Z"
   },
   {
    "duration": 3520,
    "start_time": "2022-03-12T00:26:41.625Z"
   },
   {
    "duration": 162764,
    "start_time": "2022-03-12T00:26:45.148Z"
   },
   {
    "duration": 71,
    "start_time": "2022-03-12T00:29:27.914Z"
   },
   {
    "duration": 469,
    "start_time": "2022-03-12T00:29:27.988Z"
   },
   {
    "duration": 169879,
    "start_time": "2022-03-12T00:29:28.460Z"
   },
   {
    "duration": 39,
    "start_time": "2022-03-12T00:32:18.343Z"
   },
   {
    "duration": 234159,
    "start_time": "2022-03-12T00:32:18.385Z"
   },
   {
    "duration": 473,
    "start_time": "2022-03-12T00:36:12.547Z"
   },
   {
    "duration": 322,
    "start_time": "2022-03-12T00:42:08.408Z"
   },
   {
    "duration": 1295,
    "start_time": "2022-03-12T00:51:08.012Z"
   },
   {
    "duration": 32,
    "start_time": "2022-03-12T00:51:09.310Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-12T00:51:09.346Z"
   },
   {
    "duration": 30,
    "start_time": "2022-03-12T00:51:09.382Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-12T00:51:09.415Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-12T00:51:09.424Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-12T00:51:09.436Z"
   },
   {
    "duration": 11,
    "start_time": "2022-03-12T00:51:09.483Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-12T00:51:09.497Z"
   },
   {
    "duration": 21,
    "start_time": "2022-03-12T00:51:09.505Z"
   },
   {
    "duration": 11,
    "start_time": "2022-03-12T00:51:09.529Z"
   },
   {
    "duration": 41,
    "start_time": "2022-03-12T00:51:09.543Z"
   },
   {
    "duration": 35,
    "start_time": "2022-03-12T00:51:09.587Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-12T00:51:09.624Z"
   },
   {
    "duration": 3671,
    "start_time": "2022-03-12T00:51:09.633Z"
   },
   {
    "duration": 162046,
    "start_time": "2022-03-12T00:51:13.306Z"
   },
   {
    "duration": 46,
    "start_time": "2022-03-12T00:53:55.354Z"
   },
   {
    "duration": 534,
    "start_time": "2022-03-12T00:53:55.403Z"
   },
   {
    "duration": 161202,
    "start_time": "2022-03-12T00:53:55.939Z"
   },
   {
    "duration": 18,
    "start_time": "2022-03-12T00:56:37.144Z"
   },
   {
    "duration": 236309,
    "start_time": "2022-03-12T00:56:37.164Z"
   },
   {
    "duration": 322,
    "start_time": "2022-03-12T01:00:33.482Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
